{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f94112-0845-49b6-8e91-1ac65611e2fd",
   "metadata": {},
   "source": [
    "# Question 3 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9527f-f076-465d-9616-29c08e6a92bf",
   "metadata": {},
   "source": [
    "## Setup and Initialisation\n",
    "Importing libraries and setting up the logging and creating a connection to the 'master' database created in question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81d7f4d-5e36-42b6-8ea4-79c2e2ae7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas_ta as ta\n",
    "import logging, functools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# setup logging format\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# decorator to log SQL insert operations\n",
    "def log_insert(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(\"Starting SQL insert operation.\")\n",
    "        result = func(*args, **kwargs)\n",
    "        logging.info(\"Completed SQL insert operation.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "#create connection to 'master' database\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://sa:!Hartree123!@localhost:1433/master?\"\n",
    "    \"driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "#create a session object for executing SQL commands\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7644b40-80d0-486a-9eab-4da6d1e64f7b",
   "metadata": {},
   "source": [
    "## Laod and Clean CSV Data\n",
    "This is the same code as my solutions to question 1. Consisting of data processing and conversion such as the dates into datetime. Then I added a last with statement that opens a temporary database connection to delete all data within the table if the code was already ran, so we dont have duplicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a78427-57e6-4567-bef6-a0bdeb093308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and clean it\n",
    "\n",
    "#load the marketdata file without headers\n",
    "df = pd.read_csv('/Users/giacomofiorani/Desktop/Hartree/OilDesk-Intern-Assessment/data/MarketData.csv', header=None)\n",
    "\n",
    "#drop the first 7 irrelevent rows and resetting the index\n",
    "df = df.iloc[7:].reset_index(drop=True)\n",
    "\n",
    "#renaming columns to simpler names\n",
    "df.columns = ['Dates', 'COPPER', 'ALUMINIUM', 'ZINC', 'LEAD', 'TIN', 'FUTURE']\n",
    "\n",
    "#converting dates column to datetime format\n",
    "df['Dates'] = pd.to_datetime(df['Dates'], dayfirst=True)\n",
    "\n",
    "#delete all exisiting records - this is only if the code is ran multiple times so that data is not duplicated\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DELETE FROM metal_prices\"))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f493a14-1a54-4d57-be07-52c38c53ffc7",
   "metadata": {},
   "source": [
    "## Ensuring Required Columns Exist in Database Table\n",
    "In the following code I ensure that the additional columsn required for storing MACD and RSI values exist in the metal_prices table which is within the master database. This is because when pandas_ta computes the macd and rsi it gives by default the columns a complex naming format which makes it harder to work with. Therefore, I preset them to those namings, for MACD line, signal line and the histogram. IF they already exist then they are not added, avoiding duplication and ensuring the database integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c152b1e-c899-47c7-9a5c-4337be065264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macd_fast already exists\n",
      "macds_fast already exists\n",
      "macdh_fast already exists\n",
      "macd_med already exists\n",
      "macds_med already exists\n",
      "macdh_med already exists\n",
      "macd_slow already exists\n",
      "macds_slow already exists\n",
      "macdh_slow already exists\n",
      "rsi already exists\n",
      "Database and table setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Ensuring additional columns exist in metal_prices table within master database\n",
    "with engine.connect() as conn:\n",
    "    #list of columns to add/check\n",
    "    for col in [\n",
    "        'macd_fast', 'macds_fast', 'macdh_fast',\n",
    "        'macd_med', 'macds_med', 'macdh_med',\n",
    "        'macd_slow', 'macds_slow', 'macdh_slow',\n",
    "        'rsi'\n",
    "    ]:\n",
    "        #check if column already exists in table\n",
    "        result = conn.execute(text(f\"\"\"\n",
    "            SELECT COUNT(*) FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = 'metal_prices' AND COLUMN_NAME = '{col}'\n",
    "        \"\"\")).scalar()\n",
    "\n",
    "        #if not present then add the column to the table\n",
    "        if result == 0:\n",
    "            conn.execute(text(f\"ALTER TABLE metal_prices ADD {col} FLOAT\"))\n",
    "            print(f\"{col} sucessfully added\")\n",
    "        else:\n",
    "            print(f\"{col} already exists\")\n",
    "    #commit all changes\n",
    "    conn.commit()\n",
    "#confirmation message\n",
    "print(\"Database and table setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70254b17-e01f-4877-a54f-d82119b07314",
   "metadata": {},
   "source": [
    "## Defining Metal Data Processing Function to Compute Technical Indicators and use of Joblib's Parallel and Delayed functions\n",
    "\n",
    "In the following code I created a function to process data within a temporary dataframe for a single metal within the 2020 and 2021 market data, where I compute the technical indicators. To improve the efficiency for the CPU bound tasks is use Joblilb's parallel and delayed functions to run the process_metal function. So it computes both zinc and copper concurently. After the parallel processing the dataframes are combined into one, cleaned and then converted into a list of dictionairies which will be used to bulk insert into the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a954ef6-1f82-43cd-9bf3-96b34b95e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process data for a single metal\n",
    "def process_metal(metal, df):\n",
    "    #creating temporary dataframe and copying necessary columns and renaming\n",
    "    df_temp = df[['Dates', metal]].copy()\n",
    "    df_temp = df_temp.rename(columns={metal: 'price'})\n",
    "    \n",
    "    # Filter for years 2020 and 2021\n",
    "    df_temp = df_temp[df_temp['Dates'].dt.year.isin([2020, 2021])]\n",
    "\n",
    "    #convert price to numeric values\n",
    "    df_temp['price'] = pd.to_numeric(df_temp['price'], errors='coerce')\n",
    "    \n",
    "    # Calculate indicators, RSI and MACD\n",
    "    df_temp['rsi'] = ta.rsi(df_temp['price'], length=14)\n",
    "    macd_fast = ta.macd(df_temp['price'], fast=12, slow=26, signal=9)\n",
    "    macd_med = ta.macd(df_temp['price'], fast=19, slow=39, signal=9)\n",
    "    macd_slow = ta.macd(df_temp['price'], fast=26, slow=52, signal=9)\n",
    "    \n",
    "    # Add MACD fast columns\n",
    "    df_temp['macd_fast'] = macd_fast['MACD_12_26_9']\n",
    "    df_temp['macds_fast'] = macd_fast['MACDs_12_26_9']\n",
    "    df_temp['macdh_fast'] = macd_fast['MACDh_12_26_9']\n",
    "    \n",
    "    # Add MACD medium columns\n",
    "    df_temp['macd_med'] = macd_med['MACD_19_39_9']\n",
    "    df_temp['macds_med'] = macd_med['MACDs_19_39_9']\n",
    "    df_temp['macdh_med'] = macd_med['MACDh_19_39_9']\n",
    "    \n",
    "    # Add MACD slow columns\n",
    "    df_temp['macd_slow'] = macd_slow['MACD_26_52_9']\n",
    "    df_temp['macds_slow'] = macd_slow['MACDs_26_52_9']\n",
    "    df_temp['macdh_slow'] = macd_slow['MACDh_26_52_9']\n",
    "    \n",
    "    # Add a column to identify the metal type\n",
    "    df_temp['metal'] = metal\n",
    "    return df_temp\n",
    "\n",
    "# Process both Zinc and Copper concurrently using Joblib's Parallel with delayed\n",
    "processed_dfs = Parallel(n_jobs=2)(delayed(process_metal)(metal, df) for metal in ['COPPER', 'ZINC'])\n",
    "\n",
    "# Combine both dataframes into one single dataframe\n",
    "final_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "# Rename column to match database schema\n",
    "final_df = final_df.rename(columns={'Dates': 'date'})\n",
    "\n",
    "# Replace NaN with None (for SQL compatibility)\n",
    "final_df = final_df.where(final_df.notnull(), None)\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries for bulk insert\n",
    "records = final_df.to_dict(orient='records')\n",
    "records = [{k: (None if pd.isna(v) else v) for k, v in rec.items()} for rec in records]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c111cf-50f0-46ec-bf48-f8f94bf4f05b",
   "metadata": {},
   "source": [
    "## Bulk Sql Insert Statement\n",
    "\n",
    "This code prepares a SQL statement to bulk insert records into metal_prices database table. It executes it using a list of dictionaries (record) where each dictionary represent one row of data. It uses the above records dictionary created. I used dictionaries to do the bulk insert and mainly for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f6c87ac-8860-4fd7-b498-a2037721bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 2020 and 2021 Copper and Zinc records successfully inserted.\n"
     ]
    }
   ],
   "source": [
    "# Prepare bulk insert statement\n",
    "insert_stmt = text(\"\"\"\n",
    "    INSERT INTO metal_prices (\n",
    "        date, metal, price,\n",
    "        macd_fast, macds_fast, macdh_fast,\n",
    "        macd_med, macds_med, macdh_med,\n",
    "        macd_slow, macds_slow, macdh_slow,\n",
    "        rsi\n",
    "    ) VALUES (\n",
    "        :date, :metal, :price,\n",
    "        :macd_fast, :macds_fast, :macdh_fast,\n",
    "        :macd_med, :macds_med, :macdh_med,\n",
    "        :macd_slow, :macds_slow, :macdh_slow,\n",
    "        :rsi\n",
    "    )\n",
    "\"\"\")\n",
    "# execute the bulk insert using the prepared statement and list of record dictionaries\n",
    "session.execute(insert_stmt, records)\n",
    "#commit to database\n",
    "session.commit()\n",
    "\n",
    "#confirmation message\n",
    "print(\"All 2020 and 2021 Copper and Zinc records successfully inserted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bac60c-8c7a-4001-983f-2510cc74b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
